{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba9a31f",
   "metadata": {},
   "source": [
    "# Predicción en Streaming con Spark ML y Spark Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea30cb",
   "metadata": {},
   "source": [
    "En este notebook vamos a entrenar un modelo de clasificación para predecir la probabilidad de un paciente de sufrir un ataque al corazón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6318a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4878544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56cecab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('UCI Heart disease').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afe3c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+------+----+---+-------+--------+----+-------+---+---+-----+------+\n",
      "|age|sex| cp|trtbps|chol|fbs|restecg|thalachh|exng|oldpeak|slp|caa|thall|output|\n",
      "+---+---+---+------+----+---+-------+--------+----+-------+---+---+-----+------+\n",
      "| 63|  1|  3|   145| 233|  1|      0|     150|   0|    2.3|  0|  0|    1|     1|\n",
      "| 37|  1|  2|   130| 250|  0|      1|     187|   0|    3.5|  0|  0|    2|     1|\n",
      "| 41|  0|  1|   130| 204|  0|      0|     172|   0|    1.4|  2|  0|    2|     1|\n",
      "+---+---+---+------+----+---+-------+--------+----+-------+---+---+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart = spark.read.csv('heart.csv', \n",
    "                       inferSchema = True, \n",
    "                       header = True)\n",
    "heart.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8216cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType( \\\n",
    "                     [StructField(\"age\", LongType(),True), \\\n",
    "                      StructField(\"sex\", LongType(), True), \\\n",
    "                      StructField(\"cp\", LongType(), True), \\\n",
    "                      StructField('trtbps', LongType(), True), \\\n",
    "                      StructField(\"chol\", LongType(), True), \\\n",
    "                      StructField(\"fbs\", LongType(), True), \\\n",
    "                      StructField(\"restecg\", LongType(), True), \\\n",
    "                      StructField(\"thalachh\", LongType(), True),\\\n",
    "                      StructField(\"exng\", LongType(), True), \\\n",
    "                      StructField(\"oldpeak\", DoubleType(), True), \\\n",
    "                      StructField(\"slp\", LongType(),True), \\\n",
    "                      StructField(\"caa\", LongType(), True), \\\n",
    "                      StructField(\"thall\", LongType(), True), \\\n",
    "                      StructField(\"output\", LongType(), True), \\\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28d8812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- cp: integer (nullable = true)\n",
      " |-- trtbps: integer (nullable = true)\n",
      " |-- chol: integer (nullable = true)\n",
      " |-- fbs: integer (nullable = true)\n",
      " |-- restecg: integer (nullable = true)\n",
      " |-- thalachh: integer (nullable = true)\n",
      " |-- exng: integer (nullable = true)\n",
      " |-- oldpeak: double (nullable = true)\n",
      " |-- slp: integer (nullable = true)\n",
      " |-- caa: integer (nullable = true)\n",
      " |-- thall: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StructType,StructField,LongType, StringType,DoubleType,TimestampType\n",
    "\n",
    "df = heart.withColumnRenamed(\"output\",\"label\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2c3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF, trainDF = df.randomSplit([0.3, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea2376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression model\n",
    "lr = LogisticRegression(maxIter=10, regParam= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4007600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a one hot encoder.\n",
    "ohe = OneHotEncoder(inputCols = ['sex', 'cp', 'fbs', 'restecg', 'slp', \n",
    "                                 'exng', 'caa', 'thall'], \n",
    "                    outputCols=['sex_ohe', 'cp_ohe', 'fbs_ohe', \n",
    "                                'restecg_ohe', 'slp_ohe', 'exng_ohe', \n",
    "                                'caa_ohe', 'thall_ohe'])\n",
    "\n",
    "# Input list for scaling\n",
    "inputs = ['age','trtbps','chol','thalachh','oldpeak']\n",
    "\n",
    "# We scale our inputs\n",
    "assembler1 = VectorAssembler(inputCols=inputs, outputCol=\"features_scaled1\")\n",
    "scaler = MinMaxScaler(inputCol=\"features_scaled1\", outputCol=\"features_scaled\")\n",
    "\n",
    "# We create a second assembler for the encoded columns.\n",
    "assembler2 = VectorAssembler(inputCols=['sex_ohe', 'cp_ohe', \n",
    "                                        'fbs_ohe', 'restecg_ohe', \n",
    "                                        'slp_ohe', 'exng_ohe', 'caa_ohe', \n",
    "                                        'thall_ohe','features_scaled'], \n",
    "                             outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "247fdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stages list\n",
    "myStages = [assembler1, scaler, ohe, assembler2,lr]\n",
    "\n",
    "# Set up the pipeline\n",
    "pipeline = Pipeline(stages= myStages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ab63f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|         probability|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    1|[0.04275732251570...|       1.0|\n",
      "|    1|[0.00770994745547...|       1.0|\n",
      "|    1|[0.02864864899819...|       1.0|\n",
      "|    0|[0.84423307425181...|       0.0|\n",
      "|    0|[0.63608517373059...|       0.0|\n",
      "|    1|[0.03306749779557...|       1.0|\n",
      "|    1|[0.06549242762356...|       1.0|\n",
      "|    1|[0.06549242762356...|       1.0|\n",
      "|    0|[0.64041426598065...|       0.0|\n",
      "|    1|[0.02325737111340...|       1.0|\n",
      "|    0|[0.65754290725687...|       0.0|\n",
      "|    1|[0.06216801152256...|       1.0|\n",
      "|    0|[0.91057051865391...|       0.0|\n",
      "|    1|[0.28174410550987...|       1.0|\n",
      "|    1|[0.01761146407831...|       1.0|\n",
      "|    1|[0.03817274182269...|       1.0|\n",
      "|    1|[0.01179641883045...|       1.0|\n",
      "|    0|[0.25472715497876...|       1.0|\n",
      "|    1|[0.02113471846720...|       1.0|\n",
      "|    1|[0.30261067768299...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We fit the model using the training data.\n",
    "pModel = pipeline.fit(trainDF)\n",
    "\n",
    "# We transform the data.\n",
    "trainingPred = pModel.transform(trainDF)\n",
    "\n",
    "# # We select the actual label, probability and predictions\n",
    "trainingPred.select('label','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2077daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData = testDF.repartition(10)\n",
    "testData\n",
    "\n",
    "#Create a directory\n",
    "testData.write.format(\"CSV\").option(\"header\",False).save(\"heart_streaming/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d804e85",
   "metadata": {},
   "source": [
    "## Creando predicciones en Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f8489bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceStream = (\n",
    "    spark.readStream.schema(schema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .csv(\"heart_streaming/\")\n",
    "    .withColumnRenamed(\"output\",\"label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55c9160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = pModel.transform(sourceStream).select('label',\n",
    "                                                   'probability',\n",
    "                                                   'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c6113aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: bigint, probability: vector, prediction: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(prediction1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675589c3",
   "metadata": {},
   "source": [
    "#### Mostrando las predicciones en consola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "836cdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = prediction1.writeStream.queryName(\"prediction1\") \\\n",
    "            .format(\"console\")\\\n",
    "            .trigger(once=True)\\\n",
    "            .start()\\\n",
    "            .awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530426f6",
   "metadata": {},
   "source": [
    "#### Guardando las perdicciones en Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb2672a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = (\n",
    "            prediction1.writeStream.queryName(\"prediction3\") \n",
    "            .format(\"memory\")\n",
    "            .outputMode(\"append\")\n",
    "            .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "34147a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|         probability|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    1|[0.04086978924170...|       1.0|\n",
      "|    0|[0.98184892212735...|       0.0|\n",
      "|    1|[0.00474279761632...|       1.0|\n",
      "|    1|[0.35775366097494...|       1.0|\n",
      "|    1|[0.05755909903937...|       1.0|\n",
      "|    0|[0.95305536703752...|       0.0|\n",
      "|    0|[0.94079962605713...|       0.0|\n",
      "|    0|[0.13017480179914...|       1.0|\n",
      "|    0|[0.99807916786174...|       0.0|\n",
      "|    1|[0.15541832735450...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+--------------------+----------+\n",
      "|label|         probability|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    1|[0.04086978924170...|       1.0|\n",
      "|    0|[0.98184892212735...|       0.0|\n",
      "|    1|[0.00474279761632...|       1.0|\n",
      "|    1|[0.35775366097494...|       1.0|\n",
      "|    1|[0.05755909903937...|       1.0|\n",
      "|    0|[0.95305536703752...|       0.0|\n",
      "|    0|[0.94079962605713...|       0.0|\n",
      "|    0|[0.13017480179914...|       1.0|\n",
      "|    0|[0.99807916786174...|       0.0|\n",
      "|    1|[0.15541832735450...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: bigint, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in range(2):\n",
    "    df = spark.sql(\n",
    "        \"SELECT * FROM prediction3\")\n",
    "    df.show(10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5de9cbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active[0].isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c10f0b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQueryManager at 0x192daf1e1f0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffd46c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query2.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391605d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
